# Ray Cluster Helm Values
# Chart: ray-project/ray-cluster
# https://github.com/ray-project/kuberay/tree/master/helm-chart/ray-cluster

# Ray image
image:
  repository: rayproject/ray
  tag: 2.35.0-py310
  pullPolicy: IfNotPresent

# Head node configuration
head:
  rayVersion: "2.35.0"
  
  # Resource configuration for dev
  resources:
    requests:
      cpu: "1"
      memory: "2Gi"
    limits:
      cpu: "2"
      memory: "4Gi"
  
  # Ray start parameters
  rayStartParams:
    dashboard-host: "0.0.0.0"
    block: "true"
    num-cpus: "1"
  
  # Container ports
  containerPorts:
    - name: gcs-server
      containerPort: 6379
    - name: client
      containerPort: 10001
    - name: dashboard
      containerPort: 8265
    - name: metrics
      containerPort: 8080
  
  # Service configuration
  service:
    type: ClusterIP

# Worker node configuration
worker:
  replicas: 1
  minReplicas: 0
  maxReplicas: 4
  
  # Resource configuration for dev
  resources:
    requests:
      cpu: "1"
      memory: "2Gi"
    limits:
      cpu: "2"
      memory: "4Gi"
  
  # Ray start parameters
  rayStartParams:
    block: "true"
    num-cpus: "1"

# Autoscaling configuration
autoscaling:
  enabled: true
  minReplicas: 0
  maxReplicas: 4
  
  # Autoscaler options
  upscalingMode: Default
  idleTimeoutSeconds: 60

# GPU worker group (disabled for dev, enable for GPU workloads)
# additionalWorkerGroups:
#   gpu-workers:
#     replicas: 0
#     minReplicas: 0
#     maxReplicas: 2
#     resources:
#       limits:
#         nvidia.com/gpu: 1
#       requests:
#         cpu: "2"
#         memory: "8Gi"
#     rayStartParams:
#       num-gpus: "1"

# Service account
serviceAccount:
  create: true
  name: ray-cluster

# Pod labels for service mesh and monitoring
podLabels:
  app: ray
  sidecar.istio.io/inject: "true"

# Prometheus annotations
podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "8080"
  prometheus.io/path: "/metrics"
